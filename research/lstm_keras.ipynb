{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'constants'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4104dc225bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'constants'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from constants import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = np.load('../actions.npy')\n",
    "y = np.load('../labels.npy')\n",
    "\n",
    "labels = np.unique(y)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "le_y = np.array(le.transform(y))\n",
    "le_y = le_y.reshape((-1, 1))\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(le_y)\n",
    "\n",
    "y = ohe.transform(le_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = Sequential()\n",
    "# model_lstm.add(TimeDistributed(Conv2D(128, (3, 3), strides=(1,1),activation='relu'), \n",
    "#                                 input_shape=(10, 250, 250, 1)))\n",
    "# model_lstm.add(TimeDistributed(Conv2D(64, (3, 3), strides=(1,1),activation='relu')))\n",
    "# model_lstm.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "# model_lstm.add(TimeDistributed(Conv2D(64, (3, 3), strides=(1,1),activation='relu')))\n",
    "# model_lstm.add(TimeDistributed(Conv2D(32, (3, 3), strides=(1,1),activation='relu')))\n",
    "# model_lstm.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "# model_lstm.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "\n",
    "# model_lstm.add(TimeDistributed(Flatten()))\n",
    "# model_lstm.add(Dropout(0.2))\n",
    "\n",
    "# model_lstm.add(LSTM(32, return_sequences=False, dropout=0.2)) # used 32 units\n",
    "\n",
    "# model_lstm.add(Dense(64,activation='relu'))\n",
    "# model_lstm.add(Dense(32,activation='relu'))\n",
    "# model_lstm.add(Dropout(0.2))\n",
    "# model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "# model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Dense, ConvLSTM2D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential(name=\"lstm_keras\")\n",
    "model.add(Conv1D(32, (3,), strides=(1,),activation='relu', input_shape=(window_size, num_keypoints)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(64, (3,), strides=(1,),activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True,input_shape=(window_size, num_keypoints)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(labels), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "callbacks_list_cnlst=[EarlyStopping(monitor='acc', patience=5),\n",
    "                      ModelCheckpoint(\n",
    "                                    filepath='cnn_lstm_model.h5',\n",
    "                                    monitor='val_loss',\n",
    "                                    save_best_only=True),\n",
    "                      ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 3)\n",
    "]\n",
    "\n",
    "from keras import optimizers\n",
    "optimizer_new=optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['acc', AUC(name='auc')])\n",
    "\n",
    "# model_cnlst.compile(optimizer=optimizer_new,loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                                    validation_data = (X_test, y_test),)\n",
    "                                    # callbacks = callbacks_list_cnlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Analysis after Model Training\n",
    "dirname = 'plots'\n",
    "epochs = [i for i in range(epochs)]\n",
    "train_acc = history.history['acc']\n",
    "train_auc = history.history['auc']\n",
    "train_loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_acc']\n",
    "val_auc = history.history['val_auc']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "idx = 0\n",
    "plt.rcParams['figure.figsize'] = (16, 13)\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "# plt.clf()\n",
    "plt.plot(epochs, train_acc, 'go-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.savefig(dirname + '/' + \"Acc_plot.png\",\n",
    "#             facecolor='w', transparent=False)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "# plt.clf()\n",
    "\n",
    "plt.plot(epochs, train_auc, 'go-', label='Training AUC')\n",
    "plt.plot(epochs, val_auc, 'ro-', label='Validation AUC')\n",
    "plt.title('Training & Validation AUC')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "# plt.savefig(dirname + '/' + \"AUC_plot.png\",\n",
    "#             facecolor='w', transparent=False)\n",
    "# plt.clf()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_loss, 'g-o', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
    "plt.title('Testing Accuracy & Loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.savefig(dirname + '/' + \"Loss_plot.png\",\n",
    "#             facecolor='w', transparent=False)\n",
    "# plt.clf()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# print(train_data.class_indices)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# print(cm)\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)\n",
    "# print(cm)\n",
    "g = sns.heatmap(cm, annot=True, fmt='.2f', cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "g.set_xticklabels(g.get_xticklabels(), ha='center', rotation=45)\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "figure = g.get_figure()\n",
    "# figure.savefig(dirname + '/' + 'confusion_matrix.png',\n",
    "#                 facecolor='w', transparent=False)\n",
    "# plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_loaded = load_model('lstm_keras.h5')\n",
    "\n",
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}