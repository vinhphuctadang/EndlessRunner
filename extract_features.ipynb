{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Vinh Phuc Ta Dang ft Dao Cong Tinh\n",
    "#\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import posenet\n",
    "import numpy as np\n",
    "from constants import *\n",
    "# import tensorflow as tf\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "VID_EXT_VALIDS = ['.mp4', '.mov']\n",
    "scale_factor = 0.5\n",
    "VIDEO_URI = 0\n",
    "GUI_Enable = False\n",
    "oo = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(keypoint_coords):\n",
    "    first_keypoint = keypoint_coords[0]\n",
    "    nose, feature = first_keypoint[0], []\n",
    "    mn, mx = oo, -oo\n",
    "    for i in range(1, len(first_keypoint)):\n",
    "        dist = euclidean(nose, first_keypoint[i])\n",
    "        feature.append(dist)\n",
    "\n",
    "    feature = np.array(feature)\n",
    "    mx = np.max(feature)\n",
    "    mn = np.min(feature)\n",
    "    # norm = np.linalg.norm(feature)\n",
    "    # normalized_feature = feature/norm\n",
    "    normalized_feature = np.array([(val-mn)/(mx-mn) for val in feature])\n",
    "    return normalized_feature\n",
    "\n",
    "def extractFeatures(VIDEO_URI):\n",
    "    sess = K.get_session()\n",
    "    model_cfg, model_outputs = posenet.load_model(101, sess)\n",
    "    output_stride = model_cfg['output_stride']\n",
    "\n",
    "    cap = cv2.VideoCapture(VIDEO_URI)\n",
    "    flip = False\n",
    "    cap.set(3, 257)\n",
    "    cap.set(4, 257)\n",
    "    frame_count = 0\n",
    "    frame_series, frame_seq = [], []\n",
    "\n",
    "    print('Extracting video ' + VIDEO_URI + '...')\n",
    "    while True:\n",
    "        try:\n",
    "            input_image, display_image, output_scale = posenet.read_cap(\n",
    "                cap, flip=flip, scale_factor=scale_factor, output_stride=output_stride)\n",
    "        except:\n",
    "            print(\"End video %s.%d\\n\" % (VIDEO_URI, len(frame_series)))\n",
    "            break\n",
    "\n",
    "        heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "            model_outputs,\n",
    "            feed_dict={'image:0': input_image}\n",
    "        )\n",
    "\n",
    "        pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "            heatmaps_result.squeeze(axis=0),\n",
    "            offsets_result.squeeze(axis=0),\n",
    "            displacement_fwd_result.squeeze(axis=0),\n",
    "            displacement_bwd_result.squeeze(axis=0),\n",
    "            output_stride=output_stride,\n",
    "            min_pose_score=0.15)\n",
    "            \n",
    "        keypoint_coords *= output_scale\n",
    "        normalized_feature = normalize(keypoint_coords)\n",
    "        frame_count += 1\n",
    "        frame_seq.append(normalized_feature)\n",
    "        if frame_count % window_size == 0:\n",
    "            frame_series.append(frame_seq)\n",
    "            frame_seq = []\n",
    "\n",
    "        # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "        if GUI_Enable:\n",
    "            overlay_image = posenet.draw_skel_and_kp(\n",
    "                display_image, pose_scores, keypoint_scores, keypoint_coords,\n",
    "                min_pose_score=0.15, min_part_score=0.1)\n",
    "\n",
    "            cv2.imshow('posenet', overlay_image)\n",
    "            # if \"running\" in VIDEO_URI:\n",
    "            #     filename = \"running.png\"\n",
    "            # else:\n",
    "            #     filename = \"walking.png\"\n",
    "            # cv2.imwrite(filename, overlay_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    return np.array(frame_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting video pose/datasets/running/Tinh_Running_2.mov...\n",
      "[[7.75770460e-03 5.15122961e-01]\n",
      " [7.73856831e-04 6.08819253e-01]\n",
      " [0.00000000e+00 2.45600252e-01]\n",
      " [2.29972798e-02 7.89687759e-01]\n",
      " [2.06174680e-02 1.58789830e-01]\n",
      " [1.78470705e-01 8.05972778e-01]\n",
      " [1.87210506e-01 5.54768019e-02]\n",
      " [3.50872104e-01 8.72332076e-01]\n",
      " [3.35904967e-01 0.00000000e+00]\n",
      " [5.22857741e-01 1.00000000e+00]\n",
      " [5.02983120e-01 1.45080366e-01]\n",
      " [5.26949199e-01 7.82479506e-01]\n",
      " [5.30622342e-01 1.04267027e-01]\n",
      " [7.77880381e-01 5.02342116e-01]\n",
      " [7.90137460e-01 2.69643387e-02]\n",
      " [1.00000000e+00 4.48695648e-01]\n",
      " [9.96116519e-01 4.67406093e-02]]\n",
      "[  5.94028482  15.59840484  16.63024944  20.82827443  66.36403261\n",
      "  72.4389477  130.76442503 126.9664876  195.87752801 187.62875657\n",
      " 196.05862864 198.23235921 289.94168481 295.85987018 373.5848952\n",
      " 373.05525888]\n",
      "[]\n",
      "Extracting video pose/datasets/walking/Phuc_Walking.mp4...\n",
      "[[2.27050701e-02 5.15368158e-01]\n",
      " [0.00000000e+00 6.10626755e-01]\n",
      " [6.85451926e-04 4.02514893e-01]\n",
      " [2.84184613e-02 7.23359127e-01]\n",
      " [3.76368319e-02 2.43918631e-01]\n",
      " [1.42171615e-01 7.43797119e-01]\n",
      " [1.59051383e-01 8.70522581e-02]\n",
      " [3.23889255e-01 1.00000000e+00]\n",
      " [3.32377336e-01 1.42236734e-01]\n",
      " [3.47443087e-01 9.43720002e-01]\n",
      " [4.47502323e-01 0.00000000e+00]\n",
      " [5.08795663e-01 7.05187962e-01]\n",
      " [4.74590271e-01 3.42687950e-01]\n",
      " [7.62938777e-01 6.44351265e-01]\n",
      " [7.31020981e-01 2.90368726e-01]\n",
      " [9.21632913e-01 7.99950752e-01]\n",
      " [1.00000000e+00 3.11258664e-01]]\n",
      "[ 11.57949075  12.26215297  15.96460335  21.46256083  50.62908917\n",
      "  63.28836504 125.4325171  126.5033491  133.31713097 173.59285584\n",
      " 194.05817265 180.38149306 294.86349431 282.51118471 358.53215693\n",
      " 389.38793321]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print(extractFeatures('pose/datasets/running/Tinh_Running_2.mov'))\n",
    "# print(extractFeatures('pose/datasets/walking/Phuc_Walking.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actions = np.array([])\n",
    "labels = np.array([])\n",
    "datasets_dir = 'pose/datasets'\n",
    "\n",
    "time_start = time.time()\n",
    "for action in os.listdir(datasets_dir):\n",
    "    action_dir = os.path.join(datasets_dir, action)\n",
    "    if '.DS_Store' not in action_dir:\n",
    "        print(\"\\n############# ACTION: %s #############\\n\" % action)\n",
    "        total = 0\n",
    "        for vid in os.listdir(action_dir):\n",
    "            _, ext = os.path.splitext(vid)\n",
    "            if ext in VID_EXT_VALIDS:\n",
    "                video_path = os.path.join(action_dir, vid)\n",
    "                keyPoints = extractFeatures(video_path)\n",
    "                labels = np.append(labels, np.array(\n",
    "                    [action]*keyPoints.shape[0]))\n",
    "                total += keyPoints.shape[0]\n",
    "                if len(actions) == 0:\n",
    "                    actions = keyPoints\n",
    "                else:\n",
    "                    actions = np.vstack((actions, keyPoints))\n",
    "        print(\"Total: %d\" % total)\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View result\n",
    "print('Total-time: %.6f (s)' % (time_end - time_start))\n",
    "print('actions.shape =', actions.shape)\n",
    "print('labels.shape =', labels.shape)\n",
    "\n",
    "# Store data numpy array\n",
    "np.save('normalized_actions.npy', actions)\n",
    "np.save('normalized_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}